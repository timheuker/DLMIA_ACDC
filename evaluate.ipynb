{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efede3a1-7cbb-4dbd-98c3-8da902a0aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import monai\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "#import wandb\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d4edc521-78dc-41f1-ac6b-6e6ffd101284",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = r'/home/jovyan/deeplearning'\n",
    "test_dict_list = np.load(os.path.join(data_path, 'file_list_test.npy'),allow_pickle=True)\n",
    "dia_dict_list = []\n",
    "sys_dict_list = []\n",
    "\n",
    "for i in range(len(test_dict_list)):\n",
    "    if '_f1_' in test_dict_list[i]['img']:\n",
    "        dia_dict_list.append(test_dict_list[i])\n",
    "    else:\n",
    "        sys_dict_list.append(test_dict_list[i])\n",
    "\n",
    "class LoadData(monai.transforms.Transform):\n",
    "    \"\"\"\n",
    "    This custom Monai transform loads the data from the segmentation dataset.\n",
    "    Defining a custom transform is simple; just overwrite the __init__ function and __call__ function.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys=None):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = np.load(sample['img'])\n",
    "        mask = np.load(sample['mask'])\n",
    "\n",
    "        return {'img': image, 'mask': mask, 'img_meta_dict': {'affine': np.eye(2)}, \n",
    "                'mask_meta_dict': {'affine': np.eye(2)}}\n",
    "\n",
    "def get_dataloaders(case):\n",
    "    \n",
    "    if case == 'LV':\n",
    "        train_transform = monai.transforms.Compose(\n",
    "        [\n",
    "            LoadData(),\n",
    "            monai.transforms.ThresholdIntensityd(keys=['mask'],threshold=2.5, above=True, cval=0),\n",
    "            monai.transforms.AddChanneld(keys=['img', 'mask']), # add 1 dimension because we have only 1 channel\n",
    "            monai.transforms.ScaleIntensityd(keys=['img', 'mask'],minv=0, maxv=1) # scale intensity to values between 0-1\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    elif case == 'MYO':\n",
    "        train_transform = monai.transforms.Compose(\n",
    "        [\n",
    "            LoadData(),\n",
    "            monai.transforms.ThresholdIntensityd(keys=['mask'],threshold=2.5, above=False, cval=0),\n",
    "            monai.transforms.ThresholdIntensityd(keys=['mask'],threshold=1.5, above=True, cval=0),\n",
    "            monai.transforms.AddChanneld(keys=['img', 'mask']), # add 1 dimension because we have only 1 channel\n",
    "            monai.transforms.ScaleIntensityd(keys=['img', 'mask'],minv=0, maxv=1) # scale intensity to values between 0-1\n",
    "        ]\n",
    "        )\n",
    "    \n",
    "    elif case == 'RV':\n",
    "        train_transform = monai.transforms.Compose(\n",
    "        [\n",
    "            LoadData(),\n",
    "            monai.transforms.ThresholdIntensityd(keys=['mask'],threshold=1.5, above=False, cval=0),\n",
    "            monai.transforms.AddChanneld(keys=['img', 'mask']), # add 1 dimension because we have only 1 channel\n",
    "            monai.transforms.ScaleIntensityd(keys=['img', 'mask'],minv=0, maxv=1) # scale intensity to values between 0-1\n",
    "        ]\n",
    "        )\n",
    "    \n",
    "    else: print(\"Error: select a dataloader\")\n",
    "    \n",
    "    test_dataset = monai.data.CacheDataset(test_dict_list, transform=train_transform)\n",
    "    test_loader = monai.data.DataLoader(test_dataset, batch_size=10)\n",
    "    test_loader.name = 'ALL'\n",
    "\n",
    "    dia_dataset = monai.data.CacheDataset(dia_dict_list, transform=train_transform)\n",
    "    dia_loader = monai.data.DataLoader(dia_dataset, batch_size=10)\n",
    "    dia_loader.name = 'ED'\n",
    "\n",
    "    sys_dataset = monai.data.CacheDataset(sys_dict_list, transform=train_transform)\n",
    "    sys_loader = monai.data.DataLoader(sys_dataset, batch_size=10)\n",
    "    sys_loader.name = 'ES'\n",
    "    \n",
    "    return [test_loader, dia_loader, sys_loader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3e43a504-59ec-4200-8053-50bdc16a7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = monai.networks.nets.UNet(\n",
    "    dimensions=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels = (48, 52, 104, 208, 416),\n",
    "    strides=(1, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9310cadc-098c-433b-96ff-ad0a914a47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                    \n",
    "    step = 0\n",
    "    HD_all = 0\n",
    "    cm_all = torch.zeros(1,4).to(device)\n",
    "    exclsum = 0\n",
    "    totalsum = 0\n",
    "    surf_pred_all = torch.empty(0)\n",
    "    surf_true_all = torch.empty(0)\n",
    "\n",
    "    for batch_data in test_loader:\n",
    "        step += 1\n",
    "        model.eval()\n",
    "        outputs = model(batch_data['img'].float().to(device))\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "        cm = monai.metrics.get_confusion_matrix(torch.round(outputs), batch_data['mask'].to(device))\n",
    "\n",
    "        surf_pred = torch.zeros(len(cm))\n",
    "        surf_true = torch.zeros(len(cm))\n",
    "        for k in range(len(cm)):\n",
    "            cm_all += cm[k,0]\n",
    "            surf_pred[k] = torch.round(outputs)[k].sum().item() * 1.25*1.25\n",
    "            surf_true[k] = batch_data['mask'][k].sum().item() * 1.25*1.25\n",
    "    \n",
    "        surf_pred_all = torch.cat((surf_pred_all,surf_pred),0)\n",
    "        surf_true_all = torch.cat((surf_true_all,surf_true),0)\n",
    "\n",
    "        HD = monai.metrics.compute_hausdorff_distance(torch.round(outputs), batch_data['mask'].to(device))\n",
    "        totalsum += HD.size(0)\n",
    "        HD = HD[~torch.all(HD.isinf(),dim=1)]\n",
    "        HD = HD[~torch.all(HD.isnan(),dim=1)]\n",
    "        HD1 = sum(HD)/HD.size(0)\n",
    "        HD_all += HD1.item() * 1.25\n",
    "        exclsum += HD.size(0)\n",
    "    \n",
    "    \n",
    "\n",
    "    HD_all = HD_all / step\n",
    "    dsc_cm = 2*cm_all[0,0] / (2*cm_all[0,0] + cm_all[0,1] + cm_all[0,3])\n",
    "    cormatrix = np.corrcoef(surf_pred_all.numpy(),surf_true_all.numpy())\n",
    "    MAE = np.mean(abs(surf_pred_all.numpy()-surf_true_all.numpy()))\n",
    "    surfbias =  np.mean(surf_pred_all.numpy()-surf_true_all.numpy())\n",
    "    surfstd = np.std(surf_pred_all.numpy()-surf_true_all.numpy())\n",
    "\n",
    "    print(f\"Metrics for '{model.name}' with data: '{test_loader.name}'\")\n",
    "    print(\"DSC =\", dsc_cm.item())\n",
    "    print(\"HD =\", HD_all)\n",
    "    print(\"surfCorrCoef =\", cormatrix[0,1])\n",
    "    print(\"surfMAE =\", MAE)\n",
    "    print(\"surfbias =\", surfbias)\n",
    "    print(\"surfstd =\", surfstd)\n",
    "    print(\"Number of images exclueded from the HD: \", totalsum-exclsum, \"out of\", totalsum)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f8d689a4-8b61-4d22-a5ba-af077ad2bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 476/476 [00:03<00:00, 144.63it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:01<00:00, 148.25it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:01<00:00, 145.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LVnet with data ALL\n",
      "DSC = 0.9491065144538879\n",
      "HD = 6.666590874030921\n",
      "surfCorrCoef = 0.9842838739494284\n",
      "surfMAE = 40.86791\n",
      "surfbias = -7.654937\n",
      "surfstd = 87.63697\n",
      "Number of images exclueded from the HD:  42 out of 476\n",
      "-----------------------------------\n",
      "Metrics for LVnet with data ED\n",
      "DSC = 0.9616349935531616\n",
      "HD = 4.8617445517044775\n",
      "surfCorrCoef = 0.9938480908374921\n",
      "surfMAE = 36.528362\n",
      "surfbias = -9.440651\n",
      "surfstd = 54.158188\n",
      "Number of images exclueded from the HD:  10 out of 238\n",
      "-----------------------------------\n",
      "Metrics for LVnet with data ES\n",
      "DSC = 0.926520824432373\n",
      "HD = 8.916456338411763\n",
      "surfCorrCoef = 0.9653609368910769\n",
      "surfMAE = 45.20746\n",
      "surfbias = -5.8692226\n",
      "surfstd = 111.44949\n",
      "Number of images exclueded from the HD:  32 out of 238\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 476/476 [00:02<00:00, 196.16it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:01<00:00, 148.15it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:01<00:00, 175.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for MYOnet with data ALL\n",
      "DSC = 0.8840194940567017\n",
      "HD = 8.288278381469713\n",
      "surfCorrCoef = 0.9656435466546518\n",
      "surfMAE = 73.33902\n",
      "surfbias = 16.94459\n",
      "surfstd = 109.58672\n",
      "Number of images exclueded from the HD:  23 out of 476\n",
      "-----------------------------------\n",
      "Metrics for MYOnet with data ED\n",
      "DSC = 0.8821320533752441\n",
      "HD = 7.548443751482371\n",
      "surfCorrCoef = 0.971311099262586\n",
      "surfMAE = 62.47374\n",
      "surfbias = 25.420168\n",
      "surfstd = 87.19859\n",
      "Number of images exclueded from the HD:  5 out of 238\n",
      "-----------------------------------\n",
      "Metrics for MYOnet with data ES\n",
      "DSC = 0.8856804966926575\n",
      "HD = 9.196833566608468\n",
      "surfCorrCoef = 0.9617865014829077\n",
      "surfMAE = 84.20431\n",
      "surfbias = 8.469012\n",
      "surfstd = 127.55875\n",
      "Number of images exclueded from the HD:  18 out of 238\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 476/476 [00:01<00:00, 248.51it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:00<00:00, 270.85it/s]\n",
      "Loading dataset: 100%|██████████| 238/238 [00:01<00:00, 222.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RVnet with data ALL\n",
      "DSC = 0.889615535736084\n",
      "HD = 7.903172997901467\n",
      "surfCorrCoef = 0.9470826461151706\n",
      "surfMAE = 85.23831\n",
      "surfbias = -10.04136\n",
      "surfstd = 170.64822\n",
      "Number of images exclueded from the HD:  120 out of 476\n",
      "-----------------------------------\n",
      "Metrics for RVnet with data ED\n",
      "DSC = 0.9176207780838013\n",
      "HD = 7.928793527231753\n",
      "surfCorrCoef = 0.9648092524702943\n",
      "surfMAE = 74.46822\n",
      "surfbias = -25.164127\n",
      "surfstd = 149.65637\n",
      "Number of images exclueded from the HD:  40 out of 238\n",
      "-----------------------------------\n",
      "Metrics for RVnet with data ES\n",
      "DSC = 0.8371891975402832\n",
      "HD = 8.248899106614699\n",
      "surfCorrCoef = 0.9003344559925017\n",
      "surfMAE = 96.0084\n",
      "surfbias = 5.0814075\n",
      "surfstd = 188.11488\n",
      "Number of images exclueded from the HD:  80 out of 238\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "LVnet = torch.load(os.path.join(data_path, 'trained_nets/LV_runREAL/trainedUNet_LV_runREAL.pt'))\n",
    "MYOnet = torch.load(os.path.join(data_path, 'trained_nets/MYO_runREAL/trainedUNet_MYO_runREAL.pt'))\n",
    "RVnet = torch.load(os.path.join(data_path, 'trained_nets/RV_runREAL/trainedUNet_RV_runREAL.pt'))\n",
    "\n",
    "loaders = get_dataloaders('LV')\n",
    "model.load_state_dict(LVnet)\n",
    "model.name = 'LVnet'\n",
    "for m in range(len(loaders)):\n",
    "    compute_metrics(model, loaders[m])\n",
    "\n",
    "loaders = get_dataloaders('MYO')\n",
    "model.load_state_dict(MYOnet)\n",
    "model.name = 'MYOnet'\n",
    "for m in range(len(loaders)):\n",
    "    compute_metrics(model, loaders[m])\n",
    "\n",
    "loaders = get_dataloaders('RV')\n",
    "model.load_state_dict(RVnet)\n",
    "model.name = 'RVnet'\n",
    "for m in range(len(loaders)):\n",
    "    compute_metrics(model, loaders[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c0774-aa2e-4ab2-8962-37293ee133fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
